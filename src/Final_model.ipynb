{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["-jNWY3ZcsPZt"],"mount_file_id":"12u9_3RwEwgXlABosoAWySHNSh9qU2bTL","authorship_tag":"ABX9TyPQYozNMayOVqXuxCnPN5yb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Model trained on following classification of *image forgery*(**CASIA 2.0 dataset**)\n","\n","\n","1.   Splicing\n","2.   Copy move\n","3.   Removal\n","\n","\n","\n","\n"],"metadata":{"id":"w3upL20T84H1"}},{"cell_type":"markdown","source":["# **Packages**\n","\n"],"metadata":{"id":"-jNWY3ZcsPZt"}},{"cell_type":"code","source":["!pip install torch torchvision joblib scikit-image opencv-python cycler graphviz imbalanced-learn imblearn kiwisolver matplotlib numpy pandas pyparsing python-dateutil pytz scikit-learn scipy seaborn six"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_S_7LxBTrypX","executionInfo":{"status":"ok","timestamp":1726207314392,"user_tz":-330,"elapsed":5121,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}},"outputId":"e95a2764-c712-409d-d07e-72efee287c36"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.23.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n","Collecting imblearn\n","  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n","Requirement already satisfied: kiwisolver in /usr/local/lib/python3.10/dist-packages (1.4.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (3.1.4)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (2.8.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2024.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.34.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.8.30)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n","Installing collected packages: imblearn\n","Successfully installed imblearn-0.0\n"]}]},{"cell_type":"code","source":["!pip install opencv-python-headless opencv-contrib-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJiihgCDr1Or","executionInfo":{"status":"ok","timestamp":1726207317152,"user_tz":-330,"elapsed":2772,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}},"outputId":"b0febcdf-67c9-4c67-d558-f256cb7ffffb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cp6LlVFtr3ZT","executionInfo":{"status":"ok","timestamp":1726207320640,"user_tz":-330,"elapsed":3497,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}},"outputId":"445fda50-02ae-4096-d731-a416daf88cab"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!apt-get update\n","!apt-get install -y libgl1-mesa-glx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTzRNKF3r5YV","executionInfo":{"status":"ok","timestamp":1726207343974,"user_tz":-330,"elapsed":23348,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}},"outputId":"fa24091b-3bac-4409-b968-fd0843d0f61e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [999 kB]\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Ign:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:12 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,150 kB]\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,439 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,030 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,267 kB]\n","Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,573 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,541 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,108 kB]\n","Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,309 kB]\n","Fetched 25.7 MB in 7s (3,579 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  libgl1-mesa-glx\n","0 upgraded, 1 newly installed, 0 to remove and 52 not upgraded.\n","Need to get 5,584 B of archives.\n","After this operation, 74.8 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5,584 B]\n","Fetched 5,584 B in 1s (8,510 B/s)\n","Selecting previously unselected package libgl1-mesa-glx:amd64.\n","(Reading database ... 123597 files and directories currently installed.)\n","Preparing to unpack .../libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n","Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n","Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n"]}]},{"cell_type":"code","source":["from typing import Dict\n","from torch import Tensor, stack\n","import torch\n","import math\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.optim.lr_scheduler import StepLR\n","from torch.autograd import Variable\n","import time\n","import pandas as pd\n","import torchvision.transforms as transforms\n","from torchvision import datasets\n","import glob\n","import cv2\n","from skimage.util import view_as_windows\n","import os\n","from skimage import io\n","\n","from sklearn import svm\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from matplotlib.colors import ListedColormap\n","import seaborn as sn"],"metadata":{"id":"MOxc6u_vr7w-","executionInfo":{"status":"ok","timestamp":1726207355098,"user_tz":-330,"elapsed":11154,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# **Total Model**"],"metadata":{"id":"vby1ubpusV0E"}},{"cell_type":"markdown","source":["**Architecture**"],"metadata":{"id":"tL-4LdNaRIZB"}},{"cell_type":"code","source":["import torch.nn.functional as f\n","import torch.nn as nn\n","\n","\n","\n","class CNN(nn.Module):\n","    \"\"\"\n","    The convolutional neural network (CNN) class\n","    \"\"\"\n","    def __init__(self):\n","        \"\"\"\n","        Initialization of all the layers in the network.\n","        \"\"\"\n","        super(CNN, self).__init__()\n","\n","        self.conv0 = nn.Conv2d(3, 3, kernel_size=5, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv0.weight)\n","\n","        self.conv1 = nn.Conv2d(3, 30, kernel_size=5, stride=2, padding=0)\n","        nn.init.xavier_uniform_(self.conv1.weight)\n","\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","\n","        self.conv2 = nn.Conv2d(30, 16, kernel_size=3, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv2.weight)\n","\n","        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv3.weight)\n","\n","        self.conv4 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv4.weight)\n","\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","\n","        self.conv5 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv5.weight)\n","\n","        self.conv6 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv6.weight)\n","\n","        self.conv7 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv7.weight)\n","\n","        self.conv8 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n","        nn.init.xavier_uniform_(self.conv8.weight)\n","\n","        self.fc = nn.Linear(16 * 5 * 5, 2)\n","\n","        self.drop1 = nn.Dropout(p=0.5)  # used only for the NC dataset\n","\n","    def forward(self, x):\n","        \"\"\"\n","        The forward step of the network that consumes an image patch and either uses a fully connected layer in the\n","        training phase with a softmax or just returns the feature map after the final convolutional layer.\n","        :returns: Either the output of the softmax during training or the 400-D feature representation at testing\n","        \"\"\"\n","        x = f.relu(self.conv0(x))\n","        x = f.relu(self.conv1(x))\n","        lrn = nn.LocalResponseNorm(3)\n","        x = lrn(x)\n","        x = self.pool1(x)\n","        x = f.relu(self.conv2(x))\n","        x = f.relu(self.conv3(x))\n","        x = f.relu(self.conv4(x))\n","        x = f.relu(self.conv5(x))\n","        x = lrn(x)\n","        x = self.pool2(x)\n","        x = f.relu(self.conv6(x))\n","        x = f.relu(self.conv7(x))\n","        x = f.relu(self.conv8(x))\n","        x = x.view(-1, 16 * 5 * 5)\n","\n","        # In the training phase we also need the fully connected layer with softmax\n","        if self.training:\n","            # x = self.drop1(x) # used only for the NC dataset\n","            x = f.relu(self.fc(x))\n","            x = f.softmax(x, dim=1)\n","\n","        return x"],"metadata":{"id":"01LNyzGcnBPc","executionInfo":{"status":"ok","timestamp":1726207362221,"user_tz":-330,"elapsed":628,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Function to extract patch of given image"],"metadata":{"id":"ZodZGoBaQvlh"}},{"cell_type":"code","source":["import glob\n","import cv2\n","def get_patches(image_mat, stride):\n","    \"\"\"\n","    Extract patches rom an image\n","    :param image_mat: The image as a matrix\n","    :param stride: The stride of the patch extraction process\n","    :returns: The patches\n","    \"\"\"\n","    window_shape = (128, 128, 3)\n","    windows = view_as_windows(image_mat, window_shape, step=stride)\n","    patches = []\n","    for m in range(windows.shape[0]):\n","        for n in range(windows.shape[1]):\n","            patches += [windows[m][n][0]]\n","    print(patches)\n","    return patches\n","\n","\n","def get_images_and_labels(tampered_path, authentic_path):\n","    \"\"\"\n","    Get the images and their corresponding labels\n","    :param tampered_path: The path containing the tampered images\n","    :param authentic_path: The path containing the authentic images\n","    :returns: Dictionary with images and labels\n","    \"\"\"\n","    tampered_dir = tampered_path\n","    authentic_dir = authentic_path\n","    images = {}\n","    for im in glob.glob(authentic_dir):\n","        images[im] = {}\n","        images[im]['mat'] = cv2.imread(im)\n","        images[im]['label'] = 0\n","    for im in glob.glob(tampered_dir):\n","        images[im] = {}\n","        images[im]['mat'] = cv2.imread(im)\n","        images[im]['label'] = 1\n","    return images"],"metadata":{"id":"qFAzADI-qO_c","executionInfo":{"status":"ok","timestamp":1726207363590,"user_tz":-330,"elapsed":22,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def get_yi(model, patch):\n","    \"\"\"\n","    Returns the patch's feature representation\n","    :param model: The pre-trained CNN object\n","    :param patch: The patch\n","    :returns: The 400-D feature representation of the patch\n","    \"\"\"\n","    with torch.no_grad():\n","        model.eval()\n","        return model(patch)\n","\n","\n","class WrongOperationOption(Exception):\n","    pass\n","\n","\n","def get_y_hat(y: np.ndarray, operation: str):\n","    \"\"\"\n","    Fuses the image's patches feature representation\n","    :param y: The network object\n","    :param operation: Either max or mean for the pooling operation\n","    :returns: The final 400-D feature representation of the entire image\n","    \"\"\"\n","    if operation == \"max\":\n","        return np.array(y).max(axis=0, initial=-math.inf)\n","    elif operation == \"mean\":\n","        return np.array(y).mean(axis=0)\n","    else:\n","        raise WrongOperationOption(\"The operation can be either mean or max\")"],"metadata":{"id":"8iVN8lKMqK67","executionInfo":{"status":"ok","timestamp":1726207363591,"user_tz":-330,"elapsed":21,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def create_feature_vectors(model, tampered_path, authentic_path, output_name):\n","    \"\"\"\n","    Writes the feature vectors of the CASIA2 dataset.\n","    :param model: The pre-trained CNN object\n","    :param tampered_path: The path of the tampered images of the CASIA2 dataset\n","    :param authentic_path: The path of the authentic images of the CASIA2 dataset\n","    :param output_name: The name of the output CSV that contains the feature vectors\n","    \"\"\"\n","    df = pd.DataFrame()\n","    images = get_images_and_labels(tampered_path, authentic_path)\n","    c = 1\n","    for image_name in images.keys():  # images\n","        print(\"Image: \", c)\n","\n","        image = images[image_name]['mat']\n","        label = images[image_name]['label']\n","\n","        df = pd.concat([df, pd.concat([pd.DataFrame([image_name.split(os.sep)[-1], str(label)]),\n","                                       pd.DataFrame(get_patch_yi(model, image))])], axis=1, sort=False)\n","        c += 1\n","\n","    final_df = df.T\n","    final_df.columns = get_df_column_names()\n","    final_df.to_csv(output_name, index=False)\n","    # save the feature vector to csv\n","    # csv type [im_name][label][f1,f2,...,fK]\n","\n","\n","def get_patch_yi(model, image):\n","    \"\"\"\n","    Calculates the feature representation of an image.\n","    :param model: The pre-trained CNN object\n","    :param image: The image\n","    :returns: The image's feature representation\n","    \"\"\"\n","    transform = transforms.Compose([transforms.ToTensor()])\n","\n","    y = []  # init Y\n","\n","    patches = get_patches(image, stride=1024)\n","\n","    for patch in patches:  # for every patch\n","        img_tensor = transform(patch)\n","        img_tensor.unsqueeze_(0)\n","        img_variable = Variable(img_tensor.double())\n","        yi = get_yi(model=model, patch=img_variable)\n","        y.append(yi)  # append Yi to Y\n","\n","    y = np.vstack(tuple(y))\n","\n","    y_hat = get_y_hat(y=y, operation=\"mean\")  # create Y_hat with mean or max\n","\n","    return y_hat\n","\n","\n","def get_df_column_names():\n","    \"\"\"\n","    Rename the feature csv column names as [im_names][labels][f1,f2,...,fK].\n","    :returns: The column names\n","    \"\"\"\n","    names = [\"image_names\", \"labels\"]\n","    for i in range(400):\n","        names.append(\"f\" + str(i + 1))\n","    return names"],"metadata":{"id":"jw752AKenXJR","executionInfo":{"status":"ok","timestamp":1726207363591,"user_tz":-330,"elapsed":19,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"watP3R4hmJho","executionInfo":{"status":"ok","timestamp":1726207400256,"user_tz":-330,"elapsed":4204,"user":{"displayName":"KSPSVLN Siddardha Kumar Kavuri","userId":"12765768515309216469"}},"outputId":"6bbbdfe7-a5af-4556-f8b4-8bb9df7d7660"},"outputs":[{"output_type":"stream","name":"stdout","text":["Labels are 0 for non-tampered and 1 for tampered\n","[array([[[ 54, 215, 200],\n","        [ 56, 217, 202],\n","        [ 56, 218, 206],\n","        ...,\n","        [ 43,  99,  78],\n","        [ 44, 101,  80],\n","        [ 43, 100,  79]],\n","\n","       [[ 55, 216, 201],\n","        [ 54, 217, 202],\n","        [ 56, 218, 206],\n","        ...,\n","        [ 45, 102,  81],\n","        [ 48, 105,  84],\n","        [ 50, 107,  86]],\n","\n","       [[ 53, 215, 203],\n","        [ 52, 217, 204],\n","        [ 54, 218, 207],\n","        ...,\n","        [ 46, 103,  82],\n","        [ 51, 108,  87],\n","        [ 52, 111,  90]],\n","\n","       ...,\n","\n","       [[ 43, 101,  96],\n","        [ 44, 102,  97],\n","        [ 47, 105, 100],\n","        ...,\n","        [219,  93,  58],\n","        [231, 104,  65],\n","        [233, 102,  63]],\n","\n","       [[ 45, 104, 100],\n","        [ 46, 106, 100],\n","        [ 47, 107, 101],\n","        ...,\n","        [230,  98,  61],\n","        [234, 103,  60],\n","        [239, 102,  63]],\n","\n","       [[ 47, 105, 104],\n","        [ 48, 106, 105],\n","        [ 49, 108, 104],\n","        ...,\n","        [241, 104,  66],\n","        [236,  98,  55],\n","        [232,  94,  51]]], dtype=uint8)]\n","Non tampered prediction: [0]\n","[array([[[ 22,  28,  23],\n","        [ 23,  29,  24],\n","        [ 29,  36,  31],\n","        ...,\n","        [192, 112,  81],\n","        [191, 111,  80],\n","        [191, 111,  80]],\n","\n","       [[ 19,  25,  20],\n","        [ 20,  26,  21],\n","        [ 23,  30,  25],\n","        ...,\n","        [191, 111,  80],\n","        [191, 111,  80],\n","        [191, 111,  80]],\n","\n","       [[  6,  12,   7],\n","        [  0,   6,   1],\n","        [ 13,  20,  15],\n","        ...,\n","        [190, 110,  79],\n","        [191, 111,  80],\n","        [191, 111,  80]],\n","\n","       ...,\n","\n","       [[166, 183, 186],\n","        [187, 206, 211],\n","        [156, 176, 181],\n","        ...,\n","        [ 52,  73,  70],\n","        [ 53,  74,  71],\n","        [ 52,  73,  70]],\n","\n","       [[178, 190, 194],\n","        [173, 190, 193],\n","        [144, 164, 169],\n","        ...,\n","        [ 51,  70,  67],\n","        [ 52,  73,  70],\n","        [ 55,  76,  73]],\n","\n","       [[128, 140, 144],\n","        [ 98, 113, 116],\n","        [126, 145, 148],\n","        ...,\n","        [ 49,  67,  66],\n","        [ 53,  71,  70],\n","        [ 57,  78,  76]]], dtype=uint8)]\n","Tampered prediction: [0]\n"]}],"source":["import joblib\n","import torch\n","from cv2 import imread\n","import numpy as np\n","import warnings\n","\n","# Suppress a specific warning by its type\n","warnings.filterwarnings('ignore', category=UserWarning)\n","\n","# Example that raises a UserWarning\n","\n","\n","\n","def get_feature_vector(image_path: str, model):\n","    feature_vector = np.empty((1, 400))\n","    feature_vector[0, :] = get_patch_yi(model, imread(image_path))\n","    return feature_vector\n","\n","\n","# Load the pretrained CNN with the CASIA2 dataset\n","with warnings.catch_warnings():\n","    warnings.simplefilter('ignore')\n","    with torch.no_grad():\n","      our_cnn = CNN()\n","      our_cnn=torch.load('drive/MyDrive/summer/Final/model/Cnn_50.pt',map_location=lambda storage, loc: storage)\n","      our_cnn.eval()\n","      our_cnn = our_cnn.double()\n","\n","# Load the pretrained svm model\n","svm_model = joblib.load('drive/MyDrive/summer/Final/model/svm_model.joblib')\n","\n","print(\"Labels are 0 for non-tampered and 1 for tampered\")\n","\n","# Probe the SVM model with a non-tampered image\n","non_tampered_image_path = 'Au_ani_30380.jpg'\n","non_tampered_image_feature_vector = get_feature_vector(non_tampered_image_path, our_cnn)\n","print(\"Non tampered prediction:\", svm_model.predict(non_tampered_image_feature_vector))\n","\n","# Probe the SVM model with a tampered image\n","tampered_image_path = 'Tp_D_NNN_M_N_art00099_cha00050_11760.jpg'\n","tampered_image_feature_vector = get_feature_vector(tampered_image_path, our_cnn)\n","print(\"Tampered prediction:\", svm_model.predict(tampered_image_feature_vector))"]}]}